{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnpjRbuegwCGd4L5keyhOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Preethikuppuri/Preethikuppuri/blob/main/AI%20res%20matcher%20with%20description%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DiuofhddiXf",
        "outputId": "5bd8527b-0eac-431a-a4cb-9d9d7bd0757f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gradio --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Matching logic (same as before)\n",
        "def match_resumes_to_jobs(resume_texts, job_texts):\n",
        "    processed_resumes = {f\"Resume {i+1}\": resume_texts[i] for i in range(len(resume_texts))}\n",
        "    processed_jobs = {f\"Job {i+1}\": job_texts[i] for i in range(len(job_texts))}\n",
        "\n",
        "    results = []\n",
        "    for job_name, job_text in processed_jobs.items():\n",
        "        corpus = [job_text] + list(processed_resumes.values())\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "        scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])[0]\n",
        "        for i, resume_name in enumerate(processed_resumes):\n",
        "            results.append({\n",
        "                \"Job\": job_name,\n",
        "                \"Resume\": resume_name,\n",
        "                \"Score\": round(scores[i], 4)\n",
        "            })\n",
        "    return pd.DataFrame(results).sort_values(by=\"Score\", ascending=False)\n",
        "\n",
        "# Gradio UI function\n",
        "def match_interface(resumes, jobs):\n",
        "    resume_texts = [r.decode(\"utf-8\") for r in resumes]\n",
        "    job_texts = [j.decode(\"utf-8\") for j in jobs]\n",
        "    df = match_resumes_to_jobs(resume_texts, job_texts)\n",
        "    return df\n",
        "\n",
        "# Gradio inputs\n",
        "resume_input = gr.File(file_types=[\".txt\"], file_count=\"multiple\", label=\"Upload Resumes (.txt)\")\n",
        "job_input = gr.File(file_types=[\".txt\"], file_count=\"multiple\", label=\"Upload Job Descriptions (.txt)\")\n",
        "\n",
        "# Launch app\n",
        "gr.Interface(\n",
        "    fn=match_interface,\n",
        "    inputs=[resume_input, job_input],\n",
        "    outputs=gr.Dataframe(headers=[\"Job\", \"Resume\", \"Score\"]),\n",
        "    title=\"ğŸ§  AI Resume Matcher\",\n",
        "    description=\"Upload multiple resumes and job descriptions to see how well they match!\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "A6MmFfMEdzSm",
        "outputId": "162e6c42-ca8a-4b72-e98f-3f24f1f1ba05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0c55cb5d53f6fbe5a3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0c55cb5d53f6fbe5a3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Simple stopword list\n",
        "stop_words = set(\"\"\"\n",
        "a about above after again against all am an and any are as at be because been before being below between\n",
        "both but by can cannot could did do does doing down during each few for from further had has have having he her here\n",
        "hers herself him himself his how i if in into is it its itself me more most my myself no nor not of off on once\n",
        "only or other our ours ourselves out over own same she should so some such than that the their theirs them themselves\n",
        "then there these they this those through to too under until up very was we were what when where which while who whom why\n",
        "with you your yours yourself yourselves\n",
        "\"\"\".split())\n",
        "\n",
        "# Text cleaning\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = [word for word in text.split() if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Load your files\n",
        "resume_path = \"resume.txt\"  # <- make sure resume.txt is uploaded\n",
        "job_path = \"job.txt\"        # <- make sure job.txt is uploaded\n",
        "\n",
        "with open(resume_path, \"r\") as f:\n",
        "    resume_text = f.read()\n",
        "\n",
        "with open(job_path, \"r\") as f:\n",
        "    job_text = f.read()\n",
        "\n",
        "# Preprocess\n",
        "resumes = {\"resume.txt\": preprocess(resume_text)}\n",
        "jobs = {\"job.txt\": preprocess(job_text)}\n",
        "\n",
        "# Matching logic\n",
        "def match_resumes_to_jobs(resumes, jobs):\n",
        "    all_texts = list(resumes.values()) + list(jobs.values())\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "    resume_vectors = tfidf_matrix[:len(resumes)]\n",
        "    job_vectors = tfidf_matrix[len(resumes):]\n",
        "\n",
        "    results = []\n",
        "    for r_idx, (r_name, _) in enumerate(resumes.items()):\n",
        "        for j_idx, (j_name, _) in enumerate(jobs.items()):\n",
        "            score = cosine_similarity(resume_vectors[r_idx], job_vectors[j_idx])[0][0]\n",
        "            results.append({\n",
        "                \"Resume\": r_name,\n",
        "                \"Job Description\": j_name,\n",
        "                \"Match Score\": round(score * 100, 2)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Run it!\n",
        "df = match_resumes_to_jobs(resumes, jobs)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "NY3PsOYAgj9C",
        "outputId": "4ebcefd1-a948-4477-d38d-113c34bc395e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'resume.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a3650c0a5a5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mjob_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"job.txt\"\u001b[0m        \u001b[0;31m# <- make sure job.txt is uploaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mresume_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resume.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # <- select and upload job.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "tE5lzzUdg93Y",
        "outputId": "b69da554-6cc1-4b3b-815c-feaa291a6359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-91d4536d-8bef-4828-8281-5dae983f87bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-91d4536d-8bef-4828-8281-5dae983f87bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving job.txt to job.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'job.txt': b'\\nPosition: Data Analyst\\n\\nWe are looking for a detail-oriented Data Analyst to support business decision-making.\\n\\nResponsibilities:\\n- Analyze large datasets to identify trends and insights\\n- Create reports and visualizations using tools like Excel, Tableau\\n- Collaborate with cross-functional teams to understand data needs\\n\\nRequirements:\\n- Proficiency in Python and SQL\\n- Experience with data visualization (Tableau or Power BI)\\n- Strong understanding of statistics and data modeling\\n- Excellent problem-solving and communication skills\\n\\nPreferred:\\n- Prior internship or project experience in data analysis\\n- Familiarity with cloud platforms like AWS or GCP\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload required files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import string\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Simple stopword list\n",
        "stop_words = set(\"\"\"\n",
        "a about above after again against all am an and any are as at be because been before being below between\n",
        "both but by can cannot could did do does doing down during each few for from further had has have having he her here\n",
        "hers herself him himself his how i if in into is it its itself me more most my myself no nor not of off on once\n",
        "only or other our ours ourselves out over own same she should so some such than that the their theirs them themselves\n",
        "then there these they this those through to too under until up very was we were what when where which while who whom why\n",
        "with you your yours yourself yourselves\n",
        "\"\"\".split())\n",
        "\n",
        "# Text cleaning\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = [word for word in text.split() if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Load uploaded files\n",
        "with open(\"resume.txt\", \"r\") as f:\n",
        "    resume_text = f.read()\n",
        "\n",
        "with open(\"job.txt\", \"r\") as f:\n",
        "    job_text = f.read()\n",
        "\n",
        "# Preprocess\n",
        "resumes = {\"resume.txt\": preprocess(resume_text)}\n",
        "jobs = {\"job.txt\": preprocess(job_text)}\n",
        "\n",
        "# Matching logic\n",
        "def match_resumes_to_jobs(resumes, jobs):\n",
        "    all_texts = list(resumes.values()) + list(jobs.values())\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "    resume_vectors = tfidf_matrix[:len(resumes)]\n",
        "    job_vectors = tfidf_matrix[len(resumes):]\n",
        "\n",
        "    results = []\n",
        "    for r_idx, (r_name, _) in enumerate(resumes.items()):\n",
        "        for j_idx, (j_name, _) in enumerate(jobs.items()):\n",
        "            score = cosine_similarity(resume_vectors[r_idx], job_vectors[j_idx])[0][0]\n",
        "            results.append({\n",
        "                \"Resume\": r_name,\n",
        "                \"Job Description\": j_name,\n",
        "                \"Match Score\": round(score * 100, 2)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Run it!\n",
        "df = match_resumes_to_jobs(resumes, jobs)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "WzrfnfNugt2D",
        "outputId": "0d416eb0-2fa5-41ec-cd45-c39510bb86ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-154ed71e-dcbf-4fda-9913-ab3a6ad9c07e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-154ed71e-dcbf-4fda-9913-ab3a6ad9c07e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resume.txt to resume (1).txt\n",
            "       Resume Job Description  Match Score\n",
            "0  resume.txt         job.txt        35.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload this cell after resume.txt and job.txt are uploaded\n",
        "\n",
        "import string\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Stopwords\n",
        "stop_words = set(\"\"\"\n",
        "a about above after again against all am an and any are as at be because been before being below between\n",
        "both but by can cannot could did do does doing down during each few for from further had has have having he her here\n",
        "hers herself him himself his how i if in into is it its itself me more most my myself no nor not of off on once\n",
        "only or other our ours ourselves out over own same she should so some such than that the their theirs them themselves\n",
        "then there these they this those through to too under until up very was we were what when where which while who whom why\n",
        "with you your yours yourself yourselves\n",
        "\"\"\".split())\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = [word for word in text.split() if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Matching function\n",
        "def match_resume(resume_text, job_text):\n",
        "    resumes = {\"Uploaded Resume\": preprocess(resume_text)}\n",
        "    jobs = {\"Uploaded Job\": preprocess(job_text)}\n",
        "\n",
        "    all_texts = list(resumes.values()) + list(jobs.values())\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "    resume_vector = tfidf_matrix[0]\n",
        "    job_vector = tfidf_matrix[1]\n",
        "\n",
        "    score = cosine_similarity(resume_vector, job_vector)[0][0]\n",
        "    return f\"ğŸ” Match Score: {round(score * 100, 2)}%\"\n",
        "\n",
        "# Launch Gradio app\n",
        "gr.Interface(\n",
        "    fn=match_resume,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=15, label=\"ğŸ“„ Paste Your Resume Text\"),\n",
        "        gr.Textbox(lines=10, label=\"ğŸ“ Paste Job Description\"),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Resume Matcher ğŸ’¼ğŸ¤–\",\n",
        "    description=\"Paste your resume and a job description to see how well they match!\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "3SDtvfxbhNw_",
        "outputId": "20d2d17e-5f3d-4d50-d294-1e70e2074d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9ac9917eec46d4ec36.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9ac9917eec46d4ec36.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}